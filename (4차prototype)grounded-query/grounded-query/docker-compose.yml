services:
  vllm:
    build:
      context: .
      dockerfile: Dockerfile.vllm
    environment:
      VLLM_MODEL_PATH: ${VLLM_MODEL_PATH:-/models/qwen3_4b_ft}
      VLLM_SERVED_MODEL_NAME: ${VLLM_SERVED_MODEL_NAME:-qwen3-4b-ft}
      VLLM_API_KEY: ${VLLM_API_KEY:-EMPTY}
      VLLM_HOST: 0.0.0.0
      VLLM_PORT: ${VLLM_PORT:-9000}
      VLLM_GPU_MEMORY_UTILIZATION: ${VLLM_GPU_MEMORY_UTILIZATION:-0.75}
      VLLM_MAX_NUM_SEQS: ${VLLM_MAX_NUM_SEQS:-128}
    volumes:
      - ${VLLM_MODEL_HOST_DIR:-/home/lys/Desktop/qwen3_4b_ft/final_merged_model}:${VLLM_MODEL_PATH:-/models/qwen3_4b_ft}:ro
    ports:
      - "${VLLM_PORT:-9000}:9000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities:
                - gpu

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    env_file:
      - backend/.env
    environment:
      FASTAPI_HOST: 0.0.0.0
      FASTAPI_PORT: ${FASTAPI_PORT:-8000}
      VLLM_BASE_URL: http://vllm:9000/v1
      VLLM_API_KEY: ${VLLM_API_KEY:-EMPTY}
    depends_on:
      - vllm
    volumes:
      - backend-storage:/app/backend/storage
    ports:
      - "${FASTAPI_PORT:-8000}:8000"

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
      args:
        VITE_FASTAPI_URL: ${PUBLIC_FASTAPI_URL:-http://localhost:8000}
    depends_on:
      - backend
    ports:
      - "${FRONTEND_PORT:-8080}:80"

volumes:
  backend-storage:
